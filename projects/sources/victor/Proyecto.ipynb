{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Proyecto.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yOgurIDbPBSa","colab_type":"text"},"source":["<h1>\n","  <center>\n","    CLASIFICACIÓN DE VOZ A PARTIR DE GRABACIONES CON SONIDO AMBIENTAL\n","  </center>\n","</h1>\n","<p>\n","  <center>\n","    Víctor Alfonso Mantilla Villamizar<br>\n","    Código: 2151846<br>\n","    Escuela de Ingeniería de Sistemas<br>\n","    Universidad Industrial de Santander<br>\n","    2019\n","  </center>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"OF0eT2GoVA1c","colab_type":"text"},"source":["<h2>\n","  1. Introducción\n","</h2>\n","<p align=\"justify\">\n","  En el siguiente proyecto se trata de crear una <b>inteligencia artificial </b> <sup><a href=\"https://es.wikipedia.org/wiki/Inteligencia_artificial\" target=\"_blank\">[1]</a></sup>  que tomando como base un archivo de audio cuyo contenido sea principalmente conversaciones grabadas en un entorno ruidoso en cualquier escala, sea capaz de determinar en que momentos de la grabación una o varias personas están hablando.<br>\n","  Para este propósito, primero se crea un dataset en base a información existente en internet y luego se crean diferentes modelos de inteligencias artificiales, para determinar cual de ellos es el mejor dada la solución buscada, y por último se presentan los resultados probando dicho modelo con varios archivos de audio y determinando la exactitud del modelo escogido.\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"r_q8tsduQCWz","colab_type":"text"},"source":["<h2>\n","  2. Motivación\n","</h2>\n","<p align=\"justify\">\n","  En el mundo moderno donde la Web 2.0 <sup><a href=\"https://es.wikipedia.org/wiki/Web_2.0\" target=\"_blank\">[2]</a></sup> domina todos los campos de nuestras vidas diarias, el video y el audio, juntos o separados constituyen no sólo una fuente de entretenimiento sino también de educación a distancia, de culturización y de comunicación. Sin embargo, algunas personas pueden quedar excluídas de las ventajas mencionadas, como por ejemplo aquellas que deseen consumir algún producto que esté en otro idioma que desconoce o también si posee dificultades auditivas.<br>\n","  Es debido a esto que surge la motivación de ayudar en la creación de una herramienta que permita determinar los momentos de una grabación de audio en los cuales ocurre una conversación o un monólogo, para ayudar a la fácil creación de archivos de texto de apoyo para las personas que así lo requieran.\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"VweNRdCEQhXQ","colab_type":"text"},"source":["<h2>\n","  3. Temas Abordados\n","</h2>\n","<p align=\"justify\">\n","  En este proyecto se abordan los temas:\n","  <ul>\n","    <li>Datasets (creación y manipulación de un dataset)</li>\n","    <li>Modelos de clasificación (Prueba de todos los modelos vistos para hallar el adecuado)</li>\n","  </ul>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"ecRL0MtQZFYr","colab_type":"text"},"source":["<h2>\n","  4. Funcionamiento\n","</h2>\n","<h3>\n","    4.1 Creación del Dataset\n","</h3>\n","<p align=\"justify\">\n","  El archivo a usar para crear el dataset es un archivo de audio de más de una hora de duración y un archivo de texto que contiene los tiempos en los cuales existe diálogo en este audio. este archivo está alojado en Google Drive y para poder usarlo, se ejecuta la celda:\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"tBbwmHeDgcB6","colab_type":"text"},"source":["Se importan los paquetes necesarios"]},{"cell_type":"code","metadata":{"id":"ojSOxx_I3Ytt","colab_type":"code","colab":{}},"source":["import librosa\n","import keras\n","import numpy      as np\n","import tensorflow as tf\n","\n","from google.colab                      import drive\n","from matplotlib                        import pyplot                 as plt\n","from tensorflow                        import keras\n","from keras.models                      import Sequential\n","from keras.layers                      import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from keras.optimizers                  import SGD\n","from keras.layers.advanced_activations import LeakyReLU\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zc0HdS9rlnl5","colab_type":"text"},"source":["Se carga el archivo base del dataset y se crea una imagen de la amplitud del audio en decibelios"]},{"cell_type":"code","metadata":{"id":"-4Wh0Ocs3aph","colab_type":"code","outputId":"419e8fe6-6e27-4c91-d370-e26091c29f42","executionInfo":{"status":"ok","timestamp":1566398180472,"user_tz":300,"elapsed":317282,"user":{"displayName":"Victor Mantilla","photoUrl":"","userId":"08820807981113956226"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["drive.mount('/content/drive')\n","signal, rate = librosa.load(\"drive/My Drive/Datasets/audio/audio.wav\", sr=48000)\n","signal=librosa.core.resample(signal,rate,22050)\n","rate=22050\n","hop = 256\n","win_siz= 1024\n","window = np.hanning(win_siz)\n","stft = librosa.stft(signal, n_fft = win_siz, hop_length = hop, window=window)\n","stft_magnitude, stft_phase = librosa.magphase(stft)\n","image = librosa.amplitude_to_db(stft_magnitude)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AzJADEXPgsoC","colab_type":"text"},"source":["Aquí se muestra una parte de la imagen generada."]},{"cell_type":"code","metadata":{"id":"FbstYcEqmIIJ","colab_type":"code","colab":{}},"source":["plt.figure(figsize=[100,100])\n","plt.imshow(image[:,0:10000])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aOCSw2Irm7sL","colab_type":"text"},"source":["Algunas funciones necesarias para crear las etiquetas del dataset"]},{"cell_type":"code","metadata":{"id":"SW_dYK4U3nQR","colab_type":"code","colab":{}},"source":["def timetomilis(time):\n","  parts=time.split(\":\")\n","  if(len(parts)==3):\n","    return (int(parts[0])*3600000)+(int(parts[1])*60000)+(int(parts[2].replace(\",\",\"\")))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"trM4a1fz3pwz","colab_type":"code","colab":{}},"source":["def get_labels(total,rate,filename):\n","  file_text = open(filename,\"r\")\n","  text=file_text.read()\n","  lines=text.split(\"\\n\")\n","  labels=np.zeros(total)\n","  counter=0;\n","  for i in range(len(lines)):\n","    start_stop=lines[i].split(\"\\t\")\n","    start_sample=int(timetomilis(start_stop[0])*rate/1000)\n","    stop_sample=int(timetomilis(start_stop[1])*rate/1000)\n","    labels[start_sample:stop_sample]=1\n","    counter=counter+(stop_sample-start_sample)\n","  percentage=100*counter/total\n","  print(\"Porcentaje de audio con diálogos: \"+str(round(percentage,2)))\n","  return labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yef1PsUog_na","colab_type":"text"},"source":["Con esta función se crean las características (X) y las etiquetas (y)"]},{"cell_type":"code","metadata":{"id":"5sd8v2KFXW6x","colab_type":"code","colab":{}},"source":["def get_X_y(image,labels):\n","  a,b=np.shape(image)\n","  c=len(labels)\n","  d=int(b/25)\n","  e=int(c/b)\n","  if(c<b*e):\n","    labels=np.append(labels,np.zeros(b*e-c))\n","  y=np.reshape(labels[0:b*e],[b,e])\n","  y=np.mean(y,axis=1)\n","  img=image[:,(y==0)|(y==1)]\n","  y=y[(y==0)|(y==1)]\n","  a,b=np.shape(img)\n","  c=len(labels)\n","  d=int(b/25)\n","  e=int(c/b)\n","  X=np.reshape(img[:,0:25*d],[a,25,d],order='F')\n","  y=np.reshape(y[0:25*d],[25,d],order='F')\n","  y=np.mean(y,axis=0)\n","  X=X[:,:,(y==0)|(y==1)]\n","  y=y[(y==0)|(y==1)]\n","  X=np.transpose(X,[2,0,1])\n","  return X,y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"67ZFuH2pnBjI","colab_type":"text"},"source":["Por último, se obtiene X y y"]},{"cell_type":"code","metadata":{"id":"3D3cPvxA3x7q","colab_type":"code","outputId":"e1dfa77d-f761-4402-fe04-9bd226cf17c6","executionInfo":{"status":"ok","timestamp":1566398235726,"user_tz":300,"elapsed":1939,"user":{"displayName":"Victor Mantilla","photoUrl":"","userId":"08820807981113956226"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["labels=get_labels(len(signal),rate,\"drive/My Drive/Datasets/audio/times.txt\")\n","X,y=get_X_y(image,labels)\n","print(np.shape(X))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Porcentaje de audio con diálogos: 41.5\n","(16320, 513, 25) (16320,)\n","(16320, 513, 25)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4KMfi5mCjTD1","colab_type":"text"},"source":["<h3>\n","    4.2 Creación del modelo\n","</h3>\n","<p align=\"justify\">\n","  Usando el módulo keras para python, se crea un modelo de Deep Learning para el procesamiento de los datos. Este modelo se considera el mejor para el trabajo, después de haber analizado los demás modelos de Machine Learning.\n","</p>"]},{"cell_type":"code","metadata":{"id":"8aG-G1oG6V7n","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(Conv2D(16, (3,3), padding='same', input_shape=(513, 25, 1)))\n","model.add(LeakyReLU())\n","model.add(Conv2D(16, (3,3), padding='same'))\n","model.add(LeakyReLU())\n","model.add(MaxPooling2D(pool_size=(3,3)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(16, (3,3), padding='same'))\n","model.add(LeakyReLU())\n","model.add(Conv2D(16, (3,3), padding='same'))\n","model.add(LeakyReLU())\n","model.add(MaxPooling2D(pool_size=(3,3)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(64))\n","model.add(LeakyReLU())\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation='sigmoid'))\n","sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss=keras.losses.binary_crossentropy, optimizer=sgd, metrics=['accuracy'])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xuOHOhlRjxNK","colab_type":"text"},"source":["<h3>\n","    4.3 Entrenamiento\n","</h3>\n","<p align=\"justify\">\n","  Se entrena el modelo con parte del dataset creado, teniendo la precaución de mezclarlos para garantizar aleatoriedad. Con la función siguiente se obtiene valores para train, test y reservados para la prueba del modelo.\n","</p>"]},{"cell_type":"code","metadata":{"id":"yk5kSlRs6Xie","colab_type":"code","colab":{}},"source":["def get_train_test_val(X,y,test_size=0.2):\n","  a=len(y)\n","  print(a)\n","  c=np.random.permutation(a)\n","  d=int(test_size*a)\n","  X_test=X[c[0:d],:]\n","  X_train=X[c[d:a],:]\n","  y_test=y[c[0:d]]\n","  y_train=y[c[d:a]]\n","  X_val = X_train[-1000:,:]\n","  y_val = y_train[-1000:]\n","  X_train = X_train[:-1000,:]\n","  y_train = y_train[:-1000]\n","  return X_train,y_train,X_test,y_test,X_val,y_val\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C-qYoUNykiJD","colab_type":"text"},"source":["Se consigue al fin las particiones de X_train y y_train necesarias para entrenar el modelo."]},{"cell_type":"code","metadata":{"id":"mnOzz5ew6beC","colab_type":"code","outputId":"25078629-71a4-45a2-a79b-cfa777c92ee4","colab":{"base_uri":"https://localhost:8080/","height":0}},"source":["X_train,y_train,X_test,y_test,X_val,y_val=get_train_test_val(X,y)\n","a,b,c=np.shape(X_train)\n","X_t=np.reshape(X_train,[a,b,c,1])\n","y_t=np.copy(y_train)\n","a,b,c=np.shape(X_val)\n","X_v=np.reshape(X_val,[a,b,c,1])\n","y_v=np.copy(y_val)\n","model.fit(X_t, y_t, epochs=50, verbose=1,validation_data=(X_v, y_v))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["16320\n","Train on 12056 samples, validate on 1000 samples\n","Epoch 1/50\n","12056/12056 [==============================] - 127s 11ms/step - loss: 0.7168 - acc: 0.5934 - val_loss: 0.6704 - val_acc: 0.6090\n","Epoch 2/50\n","12056/12056 [==============================] - 126s 10ms/step - loss: 0.6426 - acc: 0.6340 - val_loss: 0.6151 - val_acc: 0.6660\n","Epoch 3/50\n","12056/12056 [==============================] - 125s 10ms/step - loss: 0.6326 - acc: 0.6516 - val_loss: 0.6140 - val_acc: 0.6530\n","Epoch 4/50\n","12056/12056 [==============================] - 126s 10ms/step - loss: 0.6232 - acc: 0.6604 - val_loss: 0.6095 - val_acc: 0.6620\n","Epoch 5/50\n","12056/12056 [==============================] - 126s 10ms/step - loss: 0.6206 - acc: 0.6622 - val_loss: 0.6120 - val_acc: 0.6540\n","Epoch 6/50\n","12056/12056 [==============================] - 126s 10ms/step - loss: 0.6146 - acc: 0.6703 - val_loss: 0.6129 - val_acc: 0.6700\n","Epoch 7/50\n","12056/12056 [==============================] - 125s 10ms/step - loss: 0.6147 - acc: 0.6749 - val_loss: 0.6051 - val_acc: 0.6620\n","Epoch 8/50\n","12056/12056 [==============================] - 124s 10ms/step - loss: 0.6079 - acc: 0.6737 - val_loss: 0.6094 - val_acc: 0.6730\n","Epoch 9/50\n","12056/12056 [==============================] - 125s 10ms/step - loss: 0.6113 - acc: 0.6711 - val_loss: 0.6165 - val_acc: 0.6660\n","Epoch 10/50\n","12056/12056 [==============================] - 126s 10ms/step - loss: 0.6075 - acc: 0.6778 - val_loss: 0.6018 - val_acc: 0.6720\n","Epoch 11/50\n","12056/12056 [==============================] - 125s 10ms/step - loss: 0.6072 - acc: 0.6781 - val_loss: 0.6097 - val_acc: 0.6790\n","Epoch 12/50\n","12056/12056 [==============================] - 125s 10ms/step - loss: 0.6073 - acc: 0.6754 - val_loss: 0.6005 - val_acc: 0.6720\n","Epoch 13/50\n","12056/12056 [==============================] - 127s 10ms/step - loss: 0.6068 - acc: 0.6813 - val_loss: 0.6034 - val_acc: 0.6660\n","Epoch 14/50\n","12056/12056 [==============================] - 125s 10ms/step - loss: 0.6039 - acc: 0.6822 - val_loss: 0.6028 - val_acc: 0.6760\n","Epoch 15/50\n","12056/12056 [==============================] - 125s 10ms/step - loss: 0.6027 - acc: 0.6840 - val_loss: 0.6143 - val_acc: 0.6690\n","Epoch 16/50\n","12056/12056 [==============================] - 125s 10ms/step - loss: 0.6023 - acc: 0.6834 - val_loss: 0.6070 - val_acc: 0.6810\n","Epoch 17/50\n","12056/12056 [==============================] - 125s 10ms/step - loss: 0.6015 - acc: 0.6868 - val_loss: 0.6033 - val_acc: 0.6830\n","Epoch 18/50\n","12056/12056 [==============================] - 123s 10ms/step - loss: 0.6023 - acc: 0.6827 - val_loss: 0.6121 - val_acc: 0.6690\n","Epoch 19/50\n","12056/12056 [==============================] - 124s 10ms/step - loss: 0.5998 - acc: 0.6881 - val_loss: 0.5998 - val_acc: 0.6790\n","Epoch 20/50\n","12056/12056 [==============================] - 124s 10ms/step - loss: 0.5976 - acc: 0.6855 - val_loss: 0.6140 - val_acc: 0.6640\n","Epoch 21/50\n","12056/12056 [==============================] - 123s 10ms/step - loss: 0.5969 - acc: 0.6889 - val_loss: 0.6124 - val_acc: 0.6790\n","Epoch 22/50\n","12056/12056 [==============================] - 122s 10ms/step - loss: 0.5940 - acc: 0.6904 - val_loss: 0.6024 - val_acc: 0.6760\n","Epoch 23/50\n","12056/12056 [==============================] - 123s 10ms/step - loss: 0.5976 - acc: 0.6902 - val_loss: 0.5977 - val_acc: 0.6890\n","Epoch 24/50\n","12056/12056 [==============================] - 123s 10ms/step - loss: 0.5967 - acc: 0.6894 - val_loss: 0.6031 - val_acc: 0.6810\n","Epoch 25/50\n","12056/12056 [==============================] - 122s 10ms/step - loss: 0.5917 - acc: 0.6925 - val_loss: 0.6098 - val_acc: 0.6750\n","Epoch 26/50\n","12056/12056 [==============================] - 124s 10ms/step - loss: 0.5938 - acc: 0.6944 - val_loss: 0.5977 - val_acc: 0.6920\n","Epoch 27/50\n","12056/12056 [==============================] - 124s 10ms/step - loss: 0.5944 - acc: 0.6922 - val_loss: 0.6103 - val_acc: 0.6670\n","Epoch 28/50\n","12056/12056 [==============================] - 124s 10ms/step - loss: 0.5917 - acc: 0.6902 - val_loss: 0.6006 - val_acc: 0.6960\n","Epoch 29/50\n","12056/12056 [==============================] - 123s 10ms/step - loss: 0.5919 - acc: 0.6933 - val_loss: 0.5993 - val_acc: 0.6970\n","Epoch 30/50\n"," 3488/12056 [=======>......................] - ETA: 1:27 - loss: 0.6070 - acc: 0.6752"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"trGYr2AAkro0","colab_type":"text"},"source":["<h3>\n","    4.3 Prueba\n","</h3>\n","<p align=\"justify\">\n","Para las pruebas del modelo se usan dos fuentes de datos diferentes: datos extraídos del mismo conjunto que los datos de entrenamiento y también extraídos de una fuente secundaria y diferente. Se obtiene un resultado aceptable para los datos prpios y resultados insuficientes para los datos externos.\n","</p>"]},{"cell_type":"code","metadata":{"id":"WP11RpW2epDl","colab_type":"code","colab":{}},"source":["a,b,c=np.shape(X_test)\n","X_te=np.reshape(X_test,[a,b,c,1])\n","y_te=np.copy(y_test)\n","y_pred=model.predict(X_te)\n","mean=np.mean(y_pred)\n","y_pred=np.where(y_pred<mean,0,1)\n","print(\"Test accuracy: \"+str(np.mean (y_pred[y_te==1] == y_te[y_te==1])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7TO8KmSyW4A_","colab_type":"code","colab":{}},"source":["signal2, rate2 = librosa.load(\"drive/My Drive/Datasets/audio/second_source/Audio_2.wav\", sr=48000)\n","signal2=librosa.core.resample(signal2,rate2,22050)\n","rate2=22050\n","stft2 = librosa.stft(signal2, n_fft = win_siz, hop_length = hop, window=window)\n","stft_magnitude2, stft_phase2= librosa.magphase(stft2)\n","image2 = librosa.amplitude_to_db(stft_magnitude2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ganfGu3U1XCh","colab_type":"code","colab":{}},"source":["labels2=get_labels(len(signal2),rate2,\"drive/My Drive/Datasets/audio/second_source/text_2.txt\")\n","X2,y2=get_X_y(image2,labels2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRJ2O2QzZDM5","colab_type":"code","colab":{}},"source":["a,b,c=np.shape(X2)\n","X_te2=np.reshape(X2,[a,b,c,1])\n","y_te2=np.copy(y2)\n","y_pred2=model.predict(X_te2)\n","mean=np.mean(y_pred2)\n","y_pred2=np.where(y_pred2<mean,0,1)\n","print(\"Test accuracy: \"+str(np.mean (y_pred2[y_te2==1] == y_te2[y_te2==1])))"],"execution_count":0,"outputs":[]}]}